{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9cb1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\DL\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filterwarnings\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose,AveragePooling2D, MaxPooling2D,UpSampling2D,LeakyReLU,Softmax, concatenate, Dropout,BatchNormalization,Activation\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import  os\n",
    "import glob\n",
    "import PIL\n",
    "import cv2\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e24ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "    def __init__(self):\n",
    "        self.DataImage = []\n",
    "        self.DataLabel = []\n",
    "        self.DataID=[]\n",
    "        self.LabelImage=[]\n",
    "    #Tke image and label from Folder contain folder child (name label=name folder child)\n",
    "    def CNNFromFolder(self,pathFolder,imageType,size):\n",
    "        for dirPath in glob.glob(pathFolder+\"/*\"):\n",
    "            label = dirPath.split(\"/\")[-1]\n",
    "            for image_path in glob.glob(os.path.join(dirPath,\"*.\"+imageType)):\n",
    "                image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
    "                image = cv2.resize(image, (size[0], size[1]),interpolation = cv2.INTER_NEAREST)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                self.DataImage.append(image)\n",
    "                self.DataLabel.append(label)\n",
    "        self.DataImage=np.array(self.DataImage)\n",
    "        self.DataLabel=np.array(self.DataLabel)\n",
    "        LabelToID = {v:k for k,v in enumerate(np.unique(self.DataLabel)) }\n",
    "        IDToLabel = {v:k for k,v in LabelToID.items() }\n",
    "        self.DataID=np.array([LabelToID[i] for i in self.DataLabel])\n",
    "    #take image x and image y from Folder image y have name diff by diffStringLabel\n",
    "    def SegmentationFromFolder(self,pathFolder,imageType_X,imageType_Y,size,diffStringLabel):\n",
    "         for image_path_x in glob.glob(os.path.join(pathFolder,\"*.\"+imageType_X)):\n",
    "                if(~image_path_x.__contains__(diffStringLabel)):\n",
    "                    image_x=cv2.imread(image_path_x,cv2.IMREAD_COLOR)\n",
    "                    for image_path_y in glob.glob(os.path.join(pathFolder,\"*.\"+imageType_Y)):\n",
    "                        image_path_not_ext=os.path.splitext(image_path_x)[0]\n",
    "                        if(image_path_y==image_path_not_ext+diffStringLabel+\".\"+imageType_Y):\n",
    "                            image_y=cv2.imread(image_path_y,cv2.IMREAD_COLOR)\n",
    "                            image_x = cv2.resize(image_x, (size[0], size[1]),interpolation = cv2.INTER_NEAREST)\n",
    "                            image_x = cv2.cvtColor(image_x, cv2.COLOR_BGR2RGB)\n",
    "                            image_y= cv2.resize(image_y, (size[0], size[1]),interpolation = cv2.INTER_NEAREST)\n",
    "                            image_y = cv2.cvtColor(image_y, cv2.COLOR_BGR2RGB)\n",
    "                            self.DataImage.append(image_x)\n",
    "                            self.LabelImage.append(image_y)\n",
    "                            image_x=None\n",
    "                            image_y=None\n",
    "                            break\n",
    "         self.DataImage=np.array(self.DataImage)\n",
    "         self.LabelImage=np.array(self.LabelImage)\n",
    "         return np.array(self.DataImage),np.array(self.LabelImage)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74056384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "class ProcessDataSegmatation:\n",
    "    def __init__(self):\n",
    "        self.DataX=[]\n",
    "        self.DataY=[]\n",
    "    def RandomRotation(self,x_image, y_image):\n",
    "        rows_x,cols_x, chl_x = x_image.shape\n",
    "        rows_y,cols_y,chl_y = y_image.shape\n",
    "        rand_num = np.random.randint(-45,45)\n",
    "        M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
    "        M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
    "        x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
    "        y_image = cv2.warpAffine(y_image.astype('float'),M2,(cols_y,rows_y))\n",
    "        M1=None\n",
    "        M2=None\n",
    "        rand_num=None\n",
    "        return x_image, y_image.astype('int')\n",
    "    def Rotation(self,x_image, y_image,angle):\n",
    "        rows_x,cols_x, chl_x = x_image.shape\n",
    "        rows_y,cols_y,chl_y = y_image.shape\n",
    "        rand_num = angle\n",
    "        M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
    "        M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
    "        x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
    "        y_image = cv2.warpAffine(y_image.astype('float'),M2,(cols_y,rows_y))\n",
    "        M1=None\n",
    "        M2=None\n",
    "        rand_num=None\n",
    "        return x_image, y_image.astype('int')\n",
    "    def HorizontalFlip(self,x_image, y_image):\n",
    "        x_image = cv2.flip(x_image, 1)\n",
    "        y_image = cv2.flip(y_image.astype('float'), 1)\n",
    "        return x_image, y_image.astype('int')\n",
    "    def ImgAugmentation(self,x_train, y_train):\n",
    "        x_rotat= []\n",
    "        y_rotat= []\n",
    "        x_flip = []\n",
    "        y_flip = []\n",
    "        x_nois = []\n",
    "        for idx in range(len(x_train)):\n",
    "            x=None\n",
    "            y=None\n",
    "            x,y = self.RandomRotation(x_train[idx], y_train[idx])\n",
    "            x_rotat.append(x)\n",
    "            y_rotat.append(y)\n",
    "            x=None\n",
    "            y=None\n",
    "            x,y = self.HorizontalFlip(x_train[idx], y_train[idx])\n",
    "            x_flip.append(x)\n",
    "            y_flip.append(y)\n",
    "            x=None\n",
    "            y=None\n",
    "        return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)\n",
    "    def DataAugmentation(self,x_train,y_train):\n",
    "        x_rotated, y_rotated, x_flipped, y_flipped = self.ImgAugmentation(x_train, y_train)\n",
    "        x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n",
    "        y_train_full = np.concatenate([y_train, y_rotated, y_flipped])\n",
    "        x_rotated=None\n",
    "        y_rotated=None\n",
    "        x_flipped=None\n",
    "        y_flipped=None\n",
    "        self.DataX=x_train_full\n",
    "        self.DataY=y_train_full\n",
    "        return x_train_full,y_train_full\n",
    "    \n",
    "class ProcessDataCNN:\n",
    "    def __init__(self):\n",
    "        self.DataX=[]\n",
    "        self.DataY=[]\n",
    "    def RandomRotation(x_image, y_label):\n",
    "        rows_x,cols_x, chl_x = x_image.shape\n",
    "        rand_num = np.random.randint(-45,45)\n",
    "        M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
    "        M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
    "        x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
    "        return x_image, y_label\n",
    "    def HorizontalFlip(x_image, y_label):\n",
    "        x_image = cv2.flip(x_image, 1)\n",
    "        return x_image, y_label\n",
    "    def ImgAugmentation(x_train, y_train):\n",
    "        x_rotat= []\n",
    "        y_rotat= []\n",
    "        x_flip = []\n",
    "        y_flip = []\n",
    "        x_nois = []\n",
    "        for idx in range(len(x_train)):\n",
    "            x,y = self.RandomRotation(x_train[idx], y_train[idx])\n",
    "            x_rotat.append(x)\n",
    "            y_rotat.append(y)\n",
    "            x,y = self.HorizontalFlip(x_train[idx], y_train[idx])\n",
    "            x_flip.append(x)\n",
    "            y_flip.append(y)\n",
    "        return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)\n",
    "    def DataAugmentation(x_train,y_train):\n",
    "        x_rotated, y_rotated, x_flipped, y_flipped = self.ImgAugmentation(x_train, y_train)\n",
    "        x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n",
    "        y_train_full = np.concatenate([y_train, y_rotated, y_flipped])\n",
    "        self.DataX=x_train_full\n",
    "        self.DataY=y_train_full\n",
    "        return x_train_full,y_train_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLabel:\n",
    "    def __init__(self,ListColor,ListID,ListName):\n",
    "        self.ListColor=ListColor\n",
    "        self.ListID=ListID\n",
    "        try:\n",
    "            self.code2id = {v:k for k,v in enumerate(ListColor)}\n",
    "            self.id2code = {k:v for k,v in enumerate(ListColor)}\n",
    "            self.name2id = {v:k for k,v in enumerate(ListName)}\n",
    "            self.id2name = {k:v for k,v in enumerate(ListName)}\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "    def ImageColorToImageID(self,Image):\n",
    "        i=0\n",
    "        im=np.zeros(Image.shape)\n",
    "        for color in self.ListColor:\n",
    "            ID=self.ListID[i]\n",
    "            red, green, blue = Image[:,:,0], Image[:,:,1], Image[:,:,2] \n",
    "            mask = (red == color[0]) & (green == color[1]) & (blue == color[2])\n",
    "            im[:,:,:3][mask] = [ID[0], ID[1], ID[2]]\n",
    "            i=i+1\n",
    "        return im;\n",
    "    def ImageIDToColor(self,Image):\n",
    "        i=0;\n",
    "        im=np.zeros(Image.shape)\n",
    "        for ID in self.ListID:\n",
    "            color=self.ListColor[i]\n",
    "            id0, id1, id2 = Image[:,:,0], Image[:,:,1], Image[:,:,2] \n",
    "            mask = (id0 == ID[0]) & (id1 == ID[1]) & (id2 == ID[2])\n",
    "            im[:,:,:3][mask] = [color[0], color[1], color[2]]\n",
    "            i=i+1\n",
    "            mask=None\n",
    "            id0=None\n",
    "            id1=None\n",
    "            id2=None\n",
    "            color=None\n",
    "        return im;\n",
    "    def TranferListImageColorToListImageID(self,ListImage):\n",
    "        ListImageID=[]\n",
    "        for Image in ListImage:\n",
    "            image=self.ImageColorToImageID(Image);\n",
    "            ListImageID.append(image);\n",
    "            image=None\n",
    "        ListImageID=np.array(ListImageID)\n",
    "        return ListImageID\n",
    "    def TranferListImageIDToListImageColor(self,ListImage):\n",
    "        ListImageColor=[]\n",
    "        for Image in ListImage:\n",
    "            image=self.ImageIDToImageColor(Image);\n",
    "            ListImagecolor.append(image);\n",
    "            image=None\n",
    "        ListImageColor=np.array(ListImageColor)\n",
    "        return ListImageColor\n",
    "    def RGB_To_OneHot(self,rgb_image):\n",
    "        colormap = self.id2code\n",
    "        '''Function to one hot encode RGB mask labels\n",
    "        Inputs: \n",
    "            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n",
    "        '''\n",
    "        num_classes = len(colormap)\n",
    "        shape = rgb_image.shape[:2]+(num_classes,)\n",
    "        encoded_image = np.zeros( shape, dtype=np.int8 )\n",
    "        for i, cls in enumerate(colormap):\n",
    "            encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n",
    "        return encoded_image\n",
    "    def OneHot_To_RGB(self,onehot ):\n",
    "        colormap = self.id2code\n",
    "        '''Function to decode encoded mask labels\n",
    "            Inputs: \n",
    "            onehot - one hot encoded image matrix (height x width x num_classes)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "        '''\n",
    "        single_layer = np.argmax(onehot, axis=-1)\n",
    "        output = np.zeros( onehot.shape[:2]+(3,) )\n",
    "        for k in colormap.keys():\n",
    "            output[single_layer==k] = colormap[k]\n",
    "        return np.uint8(output)\n",
    "    def ListImageToOneHot(self,ListImageColor):\n",
    "        ListImageID=[]\n",
    "        for imgColor in ListImageColor:\n",
    "            imgID=self.RGB_To_OneHot(imgColor)\n",
    "            ListImageID.append(imgID)\n",
    "        return np.array(ListImageID)\n",
    "    def ListOneHotToImage(self,ListImageID):\n",
    "        ListImageColor=[]\n",
    "        for imgID in ListImageID:\n",
    "            imgColor=self.OneHot_To_RGB(imgID)\n",
    "            ListImageColor.append(imgColor)\n",
    "        return np.array(ListImageColor)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessImageWithTensorflow:\n",
    "    def __init__(self):\n",
    "        self.train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            rotation_range=360,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,)\n",
    "        self.test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        self.seg_trainX_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            rotation_range=360,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,)\n",
    "        self.seg_trainY_datagen = ImageDataGenerator(\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            rotation_range=360,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,)\n",
    "        self.seg_testX_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        self.seg_testY_datagen = ImageDataGenerator()\n",
    "    def FromFolder(self,pathFolder,size,batch_size):\n",
    "        train_generator,test_generator =self.train_datagen.flow_from_directory(\n",
    "            pathFolder,  # this is the target directory\n",
    "            target_size=(size[0], size[1]),  # all images will be resized to 150x150\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        return train_generator,test_generator\n",
    "    def FromFolder(self,pathTrain,pathTest,size,batch_size):\n",
    "        train_generator = self.train_datagen.flow_from_directory(\n",
    "            pathTrain,  # this is the target directory\n",
    "            target_size=(size[0], size[1]),  # all images will be resized to 150x150\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        validation_generator = self.test_datagen.flow_from_directory(\n",
    "            pathTest,\n",
    "            target_size=(size[0], size[1]),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        return train_generator,validation_generator\n",
    "    def SegmentationTrainFromImage(self,X_Train,Y_Train,seed,batch_size):\n",
    "        \n",
    "        x_train=self.seg_trainX_datagen.flow(X_Train,seed=seed,batch_size=batch_size)\n",
    "        y_train=self.seg_trainY_datagen.flow(Y_Train,seed=seed,batch_size=batch_size)\n",
    "        return zip(x_train,y_train)\n",
    "    def SegmentationTestFromImage(self,X_Test,Y_Test,seed,batch_size):\n",
    "        \n",
    "        x_test=self.seg_testX_datagen.flow(X_Test,seed=seed,batch_size=batch_size)\n",
    "        y_test=self.seg_testY_datagen.flow(Y_Test,seed=seed,batch_size=batch_size)\n",
    "        return zip(x_test,y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    " def tversky_loss(y_true, y_pred):\n",
    "    alpha = 0.5\n",
    "    beta  = 0.5\n",
    "    ones = K.ones(K.shape(y_true))\n",
    "    p0 = y_pred      # proba that voxels are class i\n",
    "    p1 = ones-y_pred # proba that voxels are not class i\n",
    "    g0 = y_true\n",
    "    g1 = ones-y_true\n",
    "    num = K.sum(p0*g0, (0,1,2,3))\n",
    "    den = num + alpha*K.sum(p0*g1,(0,1,2,3)) + beta*K.sum(p1*g0,(0,1,2,3))\n",
    "    T = K.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n",
    "    Ncl = K.cast(K.shape(y_true)[-1], 'float32')\n",
    "    return Ncl-T\n",
    "def dice_coef(y_true, y_pred,smooth):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) + smooth)\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_Weights_path = \"D:/Nam/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "\n",
    "def VGGSegnet( n_classes ,  input_height=224, input_width=224 , vgg_level=5):\n",
    "\n",
    "    img_input = Input(shape=(input_height,input_width,3))\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format='channels_last' )(img_input)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block0_pool', data_format='channels_last' )(x)\n",
    "    f0 = x\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format='channels_last' )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format='channels_last' )(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format='channels_last' )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format='channels_last' )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format='channels_last' )(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format='channels_last' )(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format='channels_last' )(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense( 1000 , activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg  = Model(  img_input , x  )\n",
    "    vgg.load_weights(VGG_Weights_path)\n",
    "\n",
    "    levels = [f1 , f2 , f3 , f4 , f5 ]\n",
    "\n",
    "    o = levels[ vgg_level ]\n",
    "\n",
    "    o = ( ZeroPadding2D( (1,1) , data_format='channels_last' ))(o)\n",
    "    o = ( Conv2D(512, (3, 3), padding='valid', data_format='channels_last'))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    o = ( UpSampling2D( (2,2), data_format='channels_last'))(o)\n",
    "    o = ( ZeroPadding2D( (1,1), data_format='channels_last'))(o)\n",
    "    o = ( Conv2D( 512, (3, 3), padding='valid', data_format='channels_last'))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    o = ( UpSampling2D( (2,2), data_format='channels_last'))(o)\n",
    "    o = ( ZeroPadding2D( (1,1), data_format='channels_last'))(o)\n",
    "    o = ( Conv2D( 256, (3, 3), padding='valid', data_format='channels_last'))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = ( UpSampling2D((2,2)  , data_format='channels_last' ) )(o)\n",
    "    o = ( ZeroPadding2D((1,1) , data_format='channels_last' ))(o)\n",
    "    o = ( Conv2D( 128 , (3, 3), padding='valid' , data_format='channels_last' ))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = ( UpSampling2D((2,2)  , data_format='channels_last' ))(o)\n",
    "    o = ( ZeroPadding2D((1,1)  , data_format='channels_last' ))(o)\n",
    "    o = ( Conv2D( 64 , (3, 3), padding='valid'  , data_format='channels_last' ))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "    \n",
    "    \n",
    "\n",
    "    o =  Conv2D( n_classes , (3, 3) , padding='same', data_format='channels_last' )( o )\n",
    "    #o_shape = Model(img_input , o ).output_shape\n",
    "    #outputHeight = o_shape[2]\n",
    "    #outputWidth = o_shape[3]\n",
    "\n",
    "    #o = (Reshape((  -1  , outputHeight*outputWidth   )))(o)\n",
    "    #o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model( img_input , o )\n",
    "    #model.outputWidth = outputWidth\n",
    "    #model.outputHeight = outputHeight\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fd83b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Resizing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 45>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m     vgg  \u001b[38;5;241m=\u001b[39m Model(  img_input , x  )\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vgg\n\u001b[1;32m---> 45\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mVGGSegnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mVGGSegnet\u001b[1;34m(n_classes, input_height, input_width, vgg_level)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mVGGSegnet\u001b[39m( n_classes ,  input_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, input_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m , vgg_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      3\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(input_height,input_width,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mResizing\u001b[49m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, crop_to_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)(img_input)\n\u001b[0;32m      7\u001b[0m     x \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock1_conv1\u001b[39m\u001b[38;5;124m'\u001b[39m, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m'\u001b[39m )(img_input)\n\u001b[0;32m      8\u001b[0m     x \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock1_conv2\u001b[39m\u001b[38;5;124m'\u001b[39m, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m'\u001b[39m )(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Resizing' is not defined"
     ]
    }
   ],
   "source": [
    "def VGGSegnet( n_classes ,  input_height=200, input_width=800 , vgg_level=5):\n",
    "\n",
    "    img_input = Input(shape=(input_height,input_width,3))\n",
    "    \n",
    "    x = Resizing(224, 224, interpolation=\"bilinear\", crop_to_aspect_ratio=False, **kwargs)(img_input)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format='channels_last' )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format='channels_last' )(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format='channels_last' )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format='channels_last' )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format='channels_last' )(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format='channels_last' )(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format='channels_last' )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format='channels_last' )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format='channels_last' )(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense( 1000 , activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg  = Model(  img_input , x  )\n",
    "    return vgg\n",
    "model=VGGSegnet(5).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f712de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_unet(n_filters = 16, bn = True, dilation_rate = 1):\n",
    "    '''Validation Image data generator\n",
    "        Inputs: \n",
    "            n_filters - base convolution filters\n",
    "            bn - flag to set batch normalization\n",
    "            dilation_rate - convolution dilation rate\n",
    "        Output: Unet keras Model\n",
    "    '''\n",
    "    #Define input batch shape\n",
    "    batch_shape=(256,256,3)\n",
    "    inputs = Input(batch_shape=(None, 256, 800, 3))\n",
    "    print(inputs)\n",
    "    \n",
    "    conv1 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(inputs)\n",
    "    if bn:\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "        \n",
    "    conv1 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv1)\n",
    "    if bn:\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool1)\n",
    "    if bn:\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "        \n",
    "    conv2 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv2)\n",
    "    if bn:\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool2)\n",
    "    if bn:\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "        \n",
    "    conv3 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv3)\n",
    "    if bn:\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "        \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool3)\n",
    "    if bn:\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "        \n",
    "    conv4 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv4)\n",
    "    if bn:\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "        \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(n_filters * 16, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool4)\n",
    "    if bn:\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "        \n",
    "    conv5 = Conv2D(n_filters * 16, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv5)\n",
    "    if bn:\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "        \n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
    "    \n",
    "    conv6 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up6)\n",
    "    if bn:\n",
    "        conv6 = BatchNormalization()(conv6)\n",
    "        \n",
    "    conv6 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv6)\n",
    "    if bn:\n",
    "        conv6 = BatchNormalization()(conv6)\n",
    "        \n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
    "    \n",
    "    conv7 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up7)\n",
    "    if bn:\n",
    "        conv7 = BatchNormalization()(conv7)\n",
    "        \n",
    "    conv7 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv7)\n",
    "    if bn:\n",
    "        conv7 = BatchNormalization()(conv7)\n",
    "        \n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n",
    "    \n",
    "    conv8 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up8)\n",
    "    if bn:\n",
    "        conv8 = BatchNormalization()(conv8)\n",
    "        \n",
    "    conv8 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv8)\n",
    "    if bn:\n",
    "        conv8 = BatchNormalization()(conv8)\n",
    "        \n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n",
    "    \n",
    "    conv9 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up9)\n",
    "    if bn:\n",
    "        conv9 = BatchNormalization()(conv9)\n",
    "        \n",
    "    conv9 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv9)\n",
    "    if bn:\n",
    "        conv9 = BatchNormalization()(conv9)\n",
    "        \n",
    "    conv10 = Conv2D(5, (1, 1), activation='softmax', padding = 'same', dilation_rate = dilation_rate)(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_Weights_path = \"D:/Nam/vgg16_weights_tf_dim_ordering_tf_kernels.h5\"\n",
    "\n",
    "IMAGE_ORDERING = 'channels_last'\n",
    "\n",
    "\n",
    "def FCN32( n_classes ,  input_height=224, input_width=224, vgg_level=3):\n",
    "\n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "\n",
    "    # https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5\n",
    "    img_input = Input(shape=(input_height,input_width,3))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense( 1000 , activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg  = Model(  img_input , x  )\n",
    "    vgg.load_weights(VGG_Weights_path)\n",
    "\n",
    "    o = f5\n",
    "\n",
    "    o = ( Conv2D( 4096 , ( 7 , 7 ) , activation='relu' , padding='same', data_format=IMAGE_ORDERING))(o)\n",
    "    o = Dropout(0.5)(o)\n",
    "    o = ( Conv2D( 4096 , ( 1 , 1 ) , activation='relu' , padding='same', data_format=IMAGE_ORDERING))(o)\n",
    "    o = Dropout(0.5)(o)\n",
    "\n",
    "    o = ( Conv2D( n_classes ,  ( 1 , 1 ) ,kernel_initializer='he_normal' , data_format=IMAGE_ORDERING))(o)\n",
    "    o = Conv2DTranspose( n_classes , kernel_size=(32,32) ,  strides=(32,32) , use_bias=False ,  data_format=IMAGE_ORDERING )(o)\n",
    "    #o_shape = Model(img_input , o ).output_shape\n",
    "\n",
    "    #outputHeight = o_shape[2]\n",
    "    #outputWidth = o_shape[3]\n",
    "\n",
    "    #print (\"koko\" , o_shape)\n",
    "\n",
    "    #o = (Reshape(( -1  , outputHeight*outputWidth   )))(o)\n",
    "    #o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model( img_input , o )\n",
    "    #model.outputWidth = outputWidth\n",
    "    #model.outputHeight = outputHeight\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb655a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = VGGSegnet( 5, vgg_level=3)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08880c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_5:0\", shape=(None, 256, 800, 3), dtype=float32)\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 256, 800, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 256, 800, 16) 448         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 256, 800, 16) 64          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 256, 800, 16) 2320        batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 256, 800, 16) 64          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 128, 400, 16) 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 400, 32) 4640        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 128, 400, 32) 128         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 128, 400, 32) 9248        batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 128, 400, 32) 128         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 200, 32)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 64, 200, 64)  18496       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 64, 200, 64)  256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 64, 200, 64)  36928       batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 64, 200, 64)  256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 100, 64)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 100, 128) 73856       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 32, 100, 128) 512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 32, 100, 128) 147584      batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 100, 128) 512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 50, 128)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 50, 256)  295168      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 16, 50, 256)  1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 50, 256)  590080      batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 50, 256)  1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 32, 100, 256) 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 100, 384) 0           up_sampling2d_12[0][0]           \n",
      "                                                                 batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 100, 128) 442496      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 100, 128) 512         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 100, 128) 147584      batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 32, 100, 128) 512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 64, 200, 128) 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 200, 192) 0           up_sampling2d_13[0][0]           \n",
      "                                                                 batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 64, 200, 64)  110656      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 64, 200, 64)  256         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 64, 200, 64)  36928       batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 64, 200, 64)  256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 128, 400, 64) 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 128, 400, 96) 0           up_sampling2d_14[0][0]           \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 128, 400, 32) 27680       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 128, 400, 32) 128         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 128, 400, 32) 9248        batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 128, 400, 32) 128         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 256, 800, 32) 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 256, 800, 48) 0           up_sampling2d_15[0][0]           \n",
      "                                                                 batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 256, 800, 16) 6928        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 256, 800, 16) 64          conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 256, 800, 16) 2320        batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 256, 800, 16) 64          conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 256, 800, 5)  85          batch_normalization_71[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,968,581\n",
      "Trainable params: 1,965,637\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = get_small_unet()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6731bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = FCN32( 5, vgg_level=3)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoadData=LoadData();\n",
    "pathFolder=\"D:/Nam/Train/Train\";\n",
    "xtrain,ytrain=LoadData.SegmentationFromFolder(pathFolder,\"bmp\",\"png\",(224,224),\"_color_mask\")\n",
    "x_train,x_test,y_train,y_test=train_test_split(xtrain,ytrain,test_size=0.2, random_state=20)\n",
    "unique_pixels = np.vstack({tuple(r) for r in y_train[1].reshape(-1,3)})\n",
    "unique_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde876c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListColor=[[0,0,0],[255,255,255],[0,60,100],[119,11,32],[150,100,100],[70,70,70]]\n",
    "ListID=[[0,0,0],[0,0,0],[0,60,100],[119,11,32],[150,100,100],[70,70,70]]\n",
    "ListName=[\"BackGroud\",\"BackGroud\",\"Bridge\",\"Fat\",\"OK\",\"Over\"]\n",
    "#Meger 2 backgound to 1 backgourd\n",
    "Label=ImageLabel(ListColor,ListID,ListName)\n",
    "y_id=Label.TranferListImageColorToListImageID(y_train)\n",
    "y_train=None\n",
    "y_test_id=Label.TranferListImageColorToListImageID(y_test)\n",
    "y_test=None\n",
    "unique_pixels = np.vstack({tuple(r) for r in y_id[1].reshape(-1,3)})\n",
    "unique_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54537e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "ListColor=[(0,0,0),(0,60,100),(119,11,32),(150,100,100),(70,70,70)]\n",
    "ListID=[(0,0,0),(1,1,1),(2,2,2),(3,3,3),(4,4,4)]\n",
    "ListName=[\"BackGroud\",\"Bridge\",\"Fat\",\"OK\",\"Over\"]\n",
    "#Meger 2 backgound to 1 backgourd\n",
    "convertLabel=ImageLabel(ListColor,ListID,ListName)\n",
    "convertLabel.id2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_id[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=convertLabel.ListImageToOneHot(y_id)\n",
    "ytest=convertLabel.ListImageToOneHot(y_test_id)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55893aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,ytrain.shape,x_test.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aug\n",
    "Aug=PreProcessImageWithTensorflow()\n",
    "DataGen_Train=Aug.SegmentationTrainFromImage(x_train,ytrain,1,16)\n",
    "DataGen_Test=Aug.SegmentationTrainFromImage(x_test,ytest,1,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='logs', write_graph=True)\n",
    "mc = ModelCheckpoint(mode='max', filepath='D:/SegSoloder6.h5', monitor='accuracy', save_best_only='True', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='min', monitor='val_loss', patience=50, verbose=1)\n",
    "callbacks = [es,mc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "steps_per_epoch = np.ceil(float(len(x_train) - round(0.2*len(x_train))) / float(batch_size))\n",
    "steps_per_epoch\n",
    "\n",
    "validation_steps = (float((round(0.2*len(x_train)))) / float(batch_size))\n",
    "validation_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 120\n",
    "batch_size = 16\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / num_epochs)\n",
    "model1.compile(optimizer=opt, loss=\"categorical_crossentropy\",  metrics=['accuracy'])\n",
    "with tf.device(\"/gpu:1\"):\n",
    "    result = model3.fit_generator(DataGen_Train, steps_per_epoch=steps_per_epoch ,\n",
    "                validation_data = DataGen_Test, \n",
    "                validation_steps =validation_steps, epochs=num_epochs, callbacks=callbacks, verbose=1)\n",
    "model3.save_weights('D:/SegSoloder6.h5', overwrite=True,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual number of epochs model was trained for\n",
    "N = len(result.history['loss'])\n",
    "\n",
    "#Plot the model evaluation history\n",
    "plt.style.use(\"ggplot\")\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(np.arange(0, N), result.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), result.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.plot(np.arange(0, N), result.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), result.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff80137",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"D:/SegSoloder10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin=cv2.imread(\"D:/Project/ProjectCustomer/TaiDoDo/mask/Train/Image_0001659697511319.bmp\",cv2.IMREAD_COLOR)\n",
    "origin = cv2.cvtColor(origin, cv2.COLOR_BGR2RGB)\n",
    "img= cv2.resize(origin, (224, 224),interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "img=img/255\n",
    "img=img.reshape(1,224,224,3)\n",
    "mask=cv2.imread(\"D:/Project/ProjectCustomer/TaiDoDo/mask/Train/Image_0001659697511319_color_mask.png\",cv2.IMREAD_COLOR)\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pred_=model.predict(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5533483",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_=pred_.reshape(224,224,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93203e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "ListColor=[(0,0,0),(0,60,100),(119,11,32),(150,100,100),(70,70,70)]\n",
    "ListID=[(0,0,0),(1,1,1),(2,2,2),(3,3,3),(4,4,4)]\n",
    "ListName=[\"BackGroud\",\"Bridge\",\"Fat\",\"OK\",\"Over\"]\n",
    "#Meger 2 backgound to 1 backgourd\n",
    "convertLabel=ImageLabel(ListColor,ListID,ListName)\n",
    "convertLabel.id2code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=convertLabel.OneHot_To_RGB(pred_)\n",
    "pred= cv2.resize(pred, (480, 500),interpolation = cv2.INTER_NEAREST)\n",
    "pred = cv2.cvtColor(pred, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cadf700",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.title(\"Origin\")\n",
    "plt.imshow(origin)\n",
    "\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.title(\"Mask\")\n",
    "plt.imshow(mask)\n",
    "\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.title(\"Predict\")\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0,100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4429584",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_[100,100,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de8b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
